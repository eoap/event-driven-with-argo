{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redis' Subscriber Implementation\n",
    "\n",
    "In event-driven architectures, efficient message consumption is essential for real-time communication between different components of a system. Redis' `subscriber` implementation enables seamless event handling using its Pub/Sub and Streams features. This approach ensures that messages published to Redis are effectively processed by multiple consumers, facilitating distributed and scalable event-driven applications. The advantages of using a subscriber include Low Latency Processing, Scalability, Decoupled Architecture, Event-Driven Workflows, and Reliable Message Processing, making it ideal for handling real-time data streams. For more information about Redis' Pub/Sub, please check this [reference](https://redis.io/docs/latest/develop/interact/pubsub/).\n",
    "\n",
    "Objectives:\n",
    "\n",
    "In this notebook, the user will:\n",
    "- Set up a Redis connection to ensure reliable event consumption.\n",
    "- Create a subscriber function that listens to Redis Streams.\n",
    "- Process incoming messages and handle them accordingly.\n",
    "- Implement consumer groups to distribute workload efficiently.\n",
    "- Acknowledge processed messages to prevent re-processing.\n",
    "- Test message reception to verify that the subscriber correctly handles events from Redis streams.\n",
    "\n",
    "### Table of content:\n",
    "- [Import dependencies](#import-dependencies)\n",
    "- [Real-Time Single-Stream Event Processing with Redis Streams and Consumer Groups](#real-time-single-stream-event-processing-with-redis-streams-and-consumer-groups)\n",
    "- [Scalable Multi-Stream Event Processing with Redis Consumer Groups](#scalable-multi-stream-event-processing-with-redis-consumer-groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time Single-Stream Event Processing with Redis Streams and Consumer Groups\n",
    "The user establishes a Redis connection to consume messages from multiple streams using Redis Streams and consumer groups. It first connects to Redis, defines stream names, and attempts to create a consumer group if it does not already exist. The message processing function (`read_stream`) continuously fetches new messages from the streams using `xreadgroup()`, decodes them, and prints the event details. After processing each message, it acknowledges receipt with `xack()` to prevent reprocessing. The script runs in an infinite loop, ensuring real-time event consumption, making it ideal for scalable, event-driven architectures where multiple consumers can process data efficiently.\n",
    "> Note: The user may prefer to execute [Scalable Multi-Stream Event Processing with Redis Consumer Groups](#scalable-multi-stream-event-processing-with-redis-consumer-groups) for the reasons mentioned in the corresponding section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration for the Redis connection\n",
    "redis_host = 'redis-service'  # Update with your Redis host\n",
    "redis_port = 6379             # Default Redis port\n",
    "redis_db = 0                  # Redis database number\n",
    "stream_name = 'WATERBODIES'           # Name of the Redis stream\n",
    "consumer_group = 'my-consumer-group'  # Consumer group name\n",
    "consumer_name = 'my-consumer'         # Unique name for the consumer\n",
    "\n",
    "# Connect to Redis\n",
    "r = redis.Redis(host=redis_host, port=redis_port, db=redis_db)\n",
    "\n",
    "streams = ['STREAM', 'WATERBODIES', \"WATERBODIESF\"] \n",
    "\n",
    "for stream in streams:\n",
    "    # Create a consumer group if it doesn't already exist\n",
    "    try:\n",
    "        r.xgroup_create(stream_name, consumer_group, id='0', mkstream=True)\n",
    "    except redis.exceptions.ResponseError as e:\n",
    "        # Ignore the error if the group already exists\n",
    "        if \"BUSYGROUP Consumer Group name already exists\" not in str(e):\n",
    "            raise\n",
    "\n",
    "# Read messages from the stream\n",
    "def read_stream():\n",
    "    try:\n",
    "        # Fetch new messages from the consumer group\n",
    "        streams = {\n",
    "            \"STREAM\": '>',\n",
    "            \"WATERBODIES\": '>',\n",
    "            \"WATERBODIESF\": '>',\n",
    "        }\n",
    "\n",
    "        messages = r.xreadgroup(consumer_group, consumer_name, streams, count=10, block=5000)\n",
    "        if messages:\n",
    "            for stream, events in messages:\n",
    "                for event_id, event_data in events:\n",
    "\n",
    "                    event_data_str = {k.decode(\"utf-8\"): v.decode(\"utf-8\") for k, v in event_data.items()}\n",
    "                    \n",
    "                    print(f\"{stream_name} - Event Id: {event_id.decode('utf-8')} Event Data: {event_data_str['message']}\")\n",
    "                    \n",
    "                    # Acknowledge the message\n",
    "                    r.xack(stream_name, consumer_group, event_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading stream: {e}\")\n",
    "\n",
    "# Continuously read from the stream\n",
    "while True:\n",
    "    read_stream()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalable Multi-Stream Event Processing with Redis Consumer Groups\n",
    "\n",
    "The user establishes a Redis connection to efficiently consume messages from multiple streams using Redis Streams and consumer groups. The script first connects to Redis, dynamically defines a list of streams, and attempts to create a consumer group for each stream if it does not already exist. This ensures that each stream is independently managed and can be consumed in scalable manner.The message processing function (`read_stream`) continuously listens to all defined streams using `xreadgroup()`, retrieves new messages, decodes them, and prints relevant details. After processing, it acknowledges each message dynamically with `xack()` in the correct stream to prevent reprocessing. The script runs in an infinite loop, enabling real-time, high-throughput event consumption across multiple streams, making it ideal for distributed systems and event-driven architectures.\n",
    "\n",
    "This implementation differs from a single-stream Redis consumer by dynamically handling multiple streams, ensuring efficient event processing across various sources. Unlike a single-stream setup, where messages are processed from a single predefined Redis stream, this script enables per-stream consumer group creation, preventing conflicts and allowing parallelized message consumption. Additionally, it acknowledges messages within their respective streams, preventing errors that might arise from incorrectly acknowledging messages in a fixed stream. By distributing workload across multiple streams, this approach ensures greater scalability, improved fault tolerance, and optimized resource utilization, making it more suitable for high-throughput applications such as real-time analytics, microservices communication, and large-scale distributed event processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STREAM - Event Id: 1739970782724-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2B_10TFK_20211230_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2B_10TFK_20211230_0_L2A'}\n",
      "STREAM - Event Id: 1739970783725-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2D_10TFK_20210708_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2D_10TFK_20210708_0_L2A'}\n",
      "STREAM - Event Id: 1739970784726-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20210708_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20210708_0_L2A'}\n",
      "STREAM - Event Id: 1739970785728-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_10TFK_20210713_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_10TFK_20210713_0_L2A'}\n",
      "STREAM - Event Id: 1739970786729-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20210718_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20210718_0_L2A'}\n",
      "STREAM - Event Id: 1739970787730-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20220524_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20220524_0_L2A'}\n",
      "STREAM - Event Id: 1739970788731-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2D_10TFK_20220524_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2D_10TFK_20220524_0_L2A'}\n",
      "STREAM - Event Id: 1739970789732-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20220514_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20220514_0_L2A'}\n",
      "STREAM - Event Id: 1739970790733-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20220504_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20220504_0_L2A'}\n",
      "STREAM - Event Id: 1739970990757-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2A_10TFK_20210708_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2A_10TFK_20210708_0_L2A'}\n",
      "STREAM - Event Id: 1739970990758-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2A_10TFK_20210708_1_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2A_10TFK_20210708_1_L2A'}\n",
      "STREAM - Event Id: 1739971103838-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2B_10TFK_20210713_1_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2B_10TFK_20210713_1_L2A'}\n",
      "STREAM - Event Id: 1739971103838-1 Event Data: {'subject': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2B_10TFK_20210713_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2B_10TFK_20210713_0_L2A'}\n",
      "WATERBODIES - Event Id: 1739971165730-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2B_10TFK_20211230_0_L2A', 'workflow_id': 'fe79fd02-3619-48a9-8777-55ac1772eda1', 'workflow_name': 'water-bodies-detection-dm2m4', 'workflow_status': 'Succeeded', 'href': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2B_10TFK_20211230_0_L2A', 'stac_catalog': 's3://results/water-bodies-detection-dm2m4-fe79fd02-3619-48a9-8777-55ac1772eda1/catalog.json'}\n",
      "WATERBODIES - Event Id: 1739971202814-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20210708_0_L2A', 'workflow_id': 'f42ed96b-75cc-4c37-8dc8-ae90f7433003', 'workflow_name': 'water-bodies-detection-6jmqs', 'workflow_status': 'Succeeded', 'href': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2A_10TFK_20210708_0_L2A', 'stac_catalog': 's3://results/water-bodies-detection-6jmqs-f42ed96b-75cc-4c37-8dc8-ae90f7433003/catalog.json'}\n",
      "STREAM - Event Id: 1739971216766-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2A_10TFK_20210718_0_L2A', 'producer': 'project-a', 'href': 'https://earth-search.aws.element84.com/v1/collections/sentinel-2-l2a/items/S2A_10TFK_20210718_0_L2A'}\n",
      "WATERBODIESFAILURE - Event Id: 1739971281805-0 Event Data: {'subject': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2D_10TFK_20210708_0_L2A', 'workflow_id': '86a5a4c2-8bdf-40c8-b183-a9ce60fdd2fe', 'workflow_name': 'water-bodies-detection-svqpn', 'workflow_status': 'Failed', 'href': 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2D_10TFK_20210708_0_L2A'}\n"
     ]
    }
   ],
   "source": [
    "# Configuration for the Redis connection\n",
    "redis_host = 'redis-service'  # Update with your Redis host\n",
    "redis_port = 6379             # Default Redis port\n",
    "redis_db = 0                  # Redis database number\n",
    "consumer_group = 'my-consumer-group'  # Consumer group name\n",
    "consumer_name = 'my-consumer'         # Unique name for the consumer\n",
    "\n",
    "# Connect to Redis\n",
    "r = redis.Redis(host=redis_host, port=redis_port, db=redis_db)\n",
    "\n",
    "# List of stream names\n",
    "streams = ['STREAM', 'WATERBODIES', 'WATERBODIESFAILURE']\n",
    "\n",
    "# Create a consumer group for each stream if it doesn't already exist\n",
    "for stream in streams:\n",
    "    try:\n",
    "        r.xgroup_create(stream, consumer_group, id='0', mkstream=True)\n",
    "    except redis.exceptions.ResponseError as e:\n",
    "        # Ignore the error if the group already exists\n",
    "        if \"BUSYGROUP Consumer Group name already exists\" not in str(e):\n",
    "            raise\n",
    "\n",
    "# Read messages from the streams\n",
    "def read_stream():\n",
    "    try:\n",
    "        # Stream dictionary with '>' for new messages\n",
    "        stream_dict = {stream: '>' for stream in streams}\n",
    "\n",
    "        # Fetch new messages from the consumer group\n",
    "        messages = r.xreadgroup(consumer_group, consumer_name, stream_dict, count=10, block=5000)\n",
    "        if messages:\n",
    "            for stream, events in messages:\n",
    "                for event_id, event_data in events:\n",
    "                    # Decode the event data\n",
    "                    event_data_str = {k.decode(\"utf-8\"): v.decode(\"utf-8\") for k, v in event_data.items()}\n",
    "                    \n",
    "                    print(f\"{stream.decode('utf-8')} - Event Id: {event_id.decode('utf-8')} Event Data: {event_data_str}\")\n",
    "\n",
    "                    # Acknowledge the message in the current stream\n",
    "                    r.xack(stream, consumer_group, event_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading stream: {e}\")\n",
    "\n",
    "# Continuously read from the streams\n",
    "while True:\n",
    "    read_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
